---
layout: post
published: Ture
category: "MICCAI2018"
title: MICCAI2018 (26 Sept 2018 Reading Notes)
subtitle: Anatomically Constrained Neural Networks (ACNN)
image: https://www.miccai.org/sites/default/files/ddb/MICCAI2018-banner.jpg
tags: [Reading Notes, MICCAI2018, Segmentation]
---

**Title:** 
MICCAI2018 

**Authors:** MICCAI

![](https://www.miccai.org/sites/default/files/ddb/MICCAI2018-banner.jpg) 


## Segmentation

### Highlights


#### **(1)** BESNet: Boundary-Enhanced Segmentation of Cells in Histopathological Images Hirohisa Oda

for the detection and semantic segmentation of cells on histopathological images

#####two strategies for enhancing the boundaries of cells: 

(1) skip connections of feature maps: the feature maps from the boundary decoding path are concatenated with the decoding path for entire cell segmentation. 

(2) adaptive weighting of loss functions: an adaptive weighting of the loss for entire cell segmentation is performed when boundaries are not enhanced strongly, because detecting such parts is difficult. 

#####Network structure of BESNet: 
BESNet has two decoding parts, Boundary Decoding Path (BDP) and Main Decoding Path (MDP). 
Feature maps in BDP are concatenated with MDP. 
Loss function for MDP is weighted by BDP output.


#####loss: Boundary-Enhanced Cross-Entropy (BECE) Loss

![](https://github.com/xuuuuuuchen/xuuuuuuchen.github.io/blob/master/img/2018-09-26-readnote/2.png?raw=true) 

#####Results: 
 Segmentation accuracy was evaluated by Dice index, precision, and recall.

The mean Dice index representing segmentation accuracy was 74.0%.

Probability threshold t was set to 0.05, 0.10, ··· , 0.95 for FROC evaluation.

The Dice index, precision, and recall of the proposed method were 71.4±31.9, was 0.50. The scores of the true positives (TPs) were computed for the highest 81.2 ± 32.9, and 67.2 ± 31 (when threshold t was 0.5)

![](https://github.com/xuuuuuuchen/xuuuuuuchen.github.io/blob/master/img/2018-09-26-readnote/1.png?raw=true) 

![](https://github.com/xuuuuuuchen/xuuuuuuchen.github.io/blob/master/img/2018-09-26-readnote/3.png?raw=true) 

![](https://github.com/xuuuuuuchen/xuuuuuuchen.github.io/blob/master/img/2018-09-26-readnote/4.png?raw=true) 


**(2)** 

**(3)** 

**(4)** 

## Problem 1

The cross-entropy loss function operates on individual pixel level class predictions, which does not guarantee global consistency and plausible anatomical shapes even though the segmentation network has a receptive field larger than the size of structures to be segmented. This is due to the fact that back-propagated gradients are parametrised only by pixel-wise individual probability divergence terms and thus provide little global context.

## Solutions

class prediction label maps are passed through the AE to obtain a lower dimensional (e.g. 64 dimensions) parametrisation of the segmentation and its underlying structure [40]. By performing AE-based non-linear lower dimensional projections on both predictions and groundtruth labels, as shown in Fig. 4, we can build our ACNN


## Methods

![](https://github.com/xuuuuuuchen/xuuuuuuchen.github.io/blob/master/img/2018-08-12-readnote/4.png?raw=true) 

## Loss function


consisting of two components:

- penalizes differences in appearance **L_sim**

And set **L_sim** to the negative local cross-correlation of M(φ) and F.

![](https://github.com/xuuuuuuchen/xuuuuuuchen.github.io/blob/master/img/2018-08-12-readnote/5.png?raw=true) 



- penalizes local spatial variations in φ **L_smooth**


![](https://github.com/xuuuuuuchen/xuuuuuuchen.github.io/blob/master/img/2018-08-12-readnote/6.png?raw=true) 



## Performance


![](https://github.com/xuuuuuuchen/xuuuuuuchen.github.io/blob/master/img/2018-08-12-readnote/7.png?raw=true) 



